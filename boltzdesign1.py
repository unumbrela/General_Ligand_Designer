import os
import sys
import argparse
import yaml
import json
import shutil
import pickle
import glob
import numpy as np
import random
import logging
import subprocess
import pandas as pd
from pathlib import Path
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=DeprecationWarning)
sys.path.append(f'{os.getcwd()}/boltzdesign')
sys.path.append(f'{os.getcwd()}/boltz/src')

from boltzdesign_utils import *
from ligandmpnn_utils import *
from alphafold_utils import *
from input_utils import *
from utils import *
import torch


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)


def str2bool(v):
    if isinstance(v, bool):
        return v
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')


def setup_gpu_environment(gpu_id):
    """Setup GPU environment variables"""
    os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)


def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description="BoltzDesign: Protein Design Pipeline with Aptamer Support",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Design protein binder for DNA target (Original mode)
  python boltzdesign.py --target_name 5zmc --target_type dna --pdb_target_ids C,D --target_mols SAM --binder_id A
  
  # Design RNA aptamer for protein target (NEW: Aptamer mode)
  python boltzdesign.py --design_mode aptamer --aptamer_type RNA --target_protein_seq "MKLLVVVGGVGSGKTTLLRQLAKEFG" --aptamer_length 40
  
  # Design DNA aptamer for protein target (NEW: Aptamer mode)  
  python boltzdesign.py --design_mode aptamer --aptamer_type DNA --target_protein_seq "MKLLVVVGGVGSGKTTLLRQLAKEFG" --aptamer_length 50
  
  # Design RNA aptamer for small molecule target (NEW: Ligand Aptamer mode)
  python boltzdesign.py --design_mode aptamer --aptamer_type RNA --target_ligand_smiles "N[C@@H](Cc1ccc(O)cc1)C(=O)O" --aptamer_length 30
  
  # Design DNA aptamer for drug molecule target (NEW: Ligand Aptamer mode)
  python boltzdesign.py --design_mode aptamer --aptamer_type DNA --target_ligand_smiles "CC(C)N(C(=O)CCC)C(C)c1ccccc1" --aptamer_length 35
        """
    )
    
    # Required arguments (Âú®ÈÄÇÈÖç‰ΩìÊ®°Âºè‰∏ãÂèØÈÄâ)
    parser.add_argument('--target_name', type=str, default='target',
                        help='Target name/PDB code (e.g., 5zmc) or custom name for aptamer mode')
    # Target configuration
    parser.add_argument('--target_type', type=str, choices=['protein', 'rna', 'dna', 'small_molecule', 'metal'],
                        default='protein', help='Type of target molecule')
    parser.add_argument('--input_type', type=str, choices=['pdb', 'custom'], default='pdb',
                        help='Input type: pdb code or custom input')
    parser.add_argument('--pdb_path', type=str, default='',
                        help='Path to a local PDB file (if specify use custom pdb, else fetch from RCSB)')
    parser.add_argument('--pdb_target_ids', type=str, default='',
                        help='Target PDB IDs (comma-separated, e.g., "C,D")')
    parser.add_argument('--target_mols', type=str, default='',
                        help='Target molecules for small molecules (comma-separated, e.g., "SAM,FAD")')
    parser.add_argument('--custom_target_input', type=str, default='',
                        help='Custom target sequences/ligand(smiles)/dna/rna/metals (comma-separated, e.g., "ATAT,GCGC", "[O-]C(=O)C(N)CC[S+](C)CC3OC(n2cnc1c(ncnc12)N)C(O)C3O", "ZN")')
    parser.add_argument('--custom_target_ids', type=str, default='',
                        help='Custom target IDs (comma-separated, e.g., "A,B")')
    parser.add_argument('--binder_id', type=str, default='A',
                        help='Binder chain ID')
    parser.add_argument('--use_msa', type=str2bool, default=False,
                        help='Use MSA (if False, runs in single-sequence mode)')
    parser.add_argument('--msa_max_seqs', type=int, default=4096,
                        help='Maximum MSA sequences')
    parser.add_argument('--suffix', type=str, default='0',
                        help='Suffix for the output directory')
    
    # Êñ∞Â¢û: ÈÄÇÈÖç‰ΩìËÆæËÆ°ÂèÇÊï∞
    parser.add_argument('--design_mode', type=str, choices=['protein', 'aptamer', 'predict_structure'], 
                       default='protein', help='Design mode: protein binder (original), aptamer design (new), or predict_structure (structure prediction only)')
    parser.add_argument('--aptamer_type', type=str, choices=['RNA', 'DNA'], 
                       default='RNA', help='Type of aptamer to design (RNA or DNA)')
    parser.add_argument('--target_protein_seq', type=str, default='',
                       help='Target protein sequence for aptamer binding (required in aptamer mode)')
    parser.add_argument('--target_ligand_smiles', type=str, default='',
                       help='Target ligand SMILES string for aptamer binding (alternative to protein)')
    parser.add_argument('--aptamer_length', type=int, default=40,
                       help='Length of aptamer to design (20-80 recommended)')
    parser.add_argument('--aptamer_chain', type=str, default='A',
                       help='Chain ID for the designed aptamer')
    parser.add_argument('--target_protein_chains', type=str, default='B',
                       help='Chain IDs for target protein (comma-separated if multiple)')
    parser.add_argument('--target_ligand_chains', type=str, default='B',
                       help='Chain IDs for target ligand (comma-separated if multiple)')
    
    # ÁªìÊûÑÈ¢ÑÊµãÂèÇÊï∞
    parser.add_argument('--predict_structure_only', type=str2bool, default=False,
                       help='Only predict structure from existing aptamer YAML file')
    parser.add_argument('--input_yaml', type=str, default='',
                       help='Input YAML file for structure prediction only mode')
    parser.add_argument('--save_structures', type=str2bool, default=True,
                       help='Save final structures in CIF and PDB formats')
    parser.add_argument('--output_format', type=str, choices=['cif', 'pdb', 'both'], default='both',
                       help='Output format for structure files')
    parser.add_argument('--structure_output_dir', type=str, default='',
                       help='Custom directory for structure outputs (default: same as aptamer output)')
    
    # Modifications
    parser.add_argument('--modifications', type=str, default='',
                        help='Modifications (comma-separated, e.g., "SEP,SEP")')
    parser.add_argument('--modifications_wt', type=str, default='',
                        help='Modifications (comma-separated, e.g., "S,S")')
    parser.add_argument('--modifications_positions', type=str, default='',
                        help='Modification positions (comma-separated, matching order)')
    parser.add_argument('--modification_target', type=str, default='',
                        help='Target ID for modifications (e.g., "A")')
    
    # Constraints
    parser.add_argument('--constraint_target', type=str, default='',
                        help='Target ID for constraints (e.g., "A")')
    parser.add_argument('--contact_residues', type=str, default='',
                        help='Contact residues for constraints (comma-separated, e.g., "99,100,109")')

    # Design parameters
    parser.add_argument('--length_min', type=int, default=100,
                        help='Minimum binder length')
    parser.add_argument('--length_max', type=int, default=150,
                        help='Maximum binder length')
    parser.add_argument('--optimizer_type', type=str, choices=['SGD', 'AdamW'], default='SGD',
                        help='Optimizer type')
    
    # Iteration parameters
    parser.add_argument('--pre_iteration', type=int, default=30,
                        help='Pre-iteration steps')
    parser.add_argument('--soft_iteration', type=int, default=75,
                        help='Soft iteration steps')
    parser.add_argument('--temp_iteration', type=int, default=50,
                        help='Temperature iteration steps')
    parser.add_argument('--hard_iteration', type=int, default=5,
                        help='Hard iteration steps')
    parser.add_argument('--semi_greedy_steps', type=int, default=2,
                        help='Semi-greedy steps')
    parser.add_argument('--recycling_steps', type=int, default=0,
                        help='Recycling steps')
    
    # Advanced configuration
    parser.add_argument('--use_default_config', type=str2bool, default=True,
                        help='Use default configuration (recommended)')
    parser.add_argument('--mask_ligand', type=str2bool, default=False,
                        help='Mask target for warm-up stage')
    parser.add_argument('--optimize_contact_per_binder_pos', type=str2bool, default=False,
                        help='Optimize interface contact per binder position')
    parser.add_argument('--distogram_only', type=str2bool, default=True,
                        help='Only use distogram for optimization')
    parser.add_argument('--design_algorithm', type=str, choices=['3stages', '3stages_extra'], 
                        default='3stages', help='Design algorithm')
    parser.add_argument('--learning_rate', type=float, default=0.1,
                        help='Learning rate for optimization')
    parser.add_argument('--learning_rate_pre', type=float, default=0.1, 
                        help='Learning rate for pre iterations (warm-up stage)')
    parser.add_argument('--e_soft', type=float, default=0.8,
                        help='Softmax temperature for 3stages')
    parser.add_argument('--e_soft_1', type=float, default=0.8,
                        help='Initial softmax temperature for 3stages_extra')
    parser.add_argument('--e_soft_2', type=float, default=1.0,
                        help='Additional softmax temperature for 3stages_extra')
    
    # Interaction parameters
    parser.add_argument('--inter_chain_cutoff', type=int, default=20,
                        help='Inter-chain distance cutoff')
    parser.add_argument('--intra_chain_cutoff', type=int, default=14,
                        help='Intra-chain distance cutoff')
    parser.add_argument('--num_inter_contacts', type=int, default=1,
                        help='Number of inter-chain contacts')
    parser.add_argument('--num_intra_contacts', type=int, default=2,
                        help='Number of intra-chain contacts')
    

    # loss parameters
    parser.add_argument('--con_loss', type=float, default=1.0,
                        help='Contact loss weight')
    parser.add_argument('--i_con_loss', type=float, default=1.0,
                        help='Inter-chain contact loss weight')
    parser.add_argument('--plddt_loss', type=float, default=0.1,
                        help='pLDDT loss weight')
    parser.add_argument('--pae_loss', type=float, default=0.4,
                        help='PAE loss weight')
    parser.add_argument('--i_pae_loss', type=float, default=0.1,
                        help='Inter-chain PAE loss weight')
    parser.add_argument('--rg_loss', type=float, default=0.0,
                        help='Radius of gyration loss weight')
    parser.add_argument('--helix_loss_max', type=float, default=0.0,
                        help='Maximum helix loss weights')
    parser.add_argument('--helix_loss_min', type=float, default=-0.3,
                        help='Minimum helix loss weights')

    
    # LigandMPNN parameters
    parser.add_argument('--num_designs', type=int, default=2,
                        help='Number of designs per PDB for LigandMPNN')
    parser.add_argument('--cutoff', type=int, default=4,
                        help='Cutoff distance for interface residues (Angstroms)')
    parser.add_argument('--i_ptm_cutoff', type=float, default=0.5,
                        help='iPTM cutoff for redesign')
    parser.add_argument('--complex_plddt_cutoff', type=float, default=0.7,
                        help='Complex pLDDT cutoff for high confidence designs')
    
    # System configuration
    parser.add_argument('--gpu_id', type=int, default=0,
                        help='GPU ID to use')
    parser.add_argument('--design_samples', type=int, default=1,
                        help='Number of design samples')
    parser.add_argument('--work_dir', type=str, default=None,
                        help='Working directory (default: current directory)')
    parser.add_argument('--high_iptm', type=str2bool, default=True,
                        help='Disable high iPTM designs')
    # Paths
    parser.add_argument('--boltz_checkpoint', type=str,
        default='/home/zihao/.boltz/boltz1_conf.ckpt',
        help='Path to Boltz checkpoint')
    parser.add_argument('--ccd_path', type=str,
        default='/home/zihao/.boltz/ccd.pkl',
        help='Path to CCD file')
    parser.add_argument('--alphafold_dir', type=str,
        default='~/alphafold3',
        help='AlphaFold directory')
    parser.add_argument('--af3_docker_name', type=str,
        default='alphafold3',
        help='Docker name')
    parser.add_argument('--af3_database_settings', type=str,
        default='~/alphafold3/alphafold3_data_save',
        help='AlphaFold3 database settings')
    parser.add_argument('--af3_hmmer_path', type=str,
        default='/home/jupyter-yehlin/.conda/envs/alphafold3_venv',
        help='AlphaFold3 hmmer path, required for RNA MSA generation')
    # Control flags
    parser.add_argument('--run_boltz_design', type=str2bool, default=True,
                        help='Run Boltz design step')
    parser.add_argument('--run_ligandmpnn', type=str2bool, default=True,
                        help='Run LigandMPNN redesign step')
    parser.add_argument('--run_alphafold', type=str2bool, default=True,
                        help='Run AlphaFold validation step')
    parser.add_argument('--run_rosetta', type=str2bool, default=True,
                        help='Run Rosetta energy calculation (protein targets only)')
    parser.add_argument('--redo_boltz_predict', type=str2bool, default=False,
                        help='Redo Boltz prediction')


    ## Visualization
    parser.add_argument('--show_animation', type=str2bool, default=True,
                        help='Show animation')
    parser.add_argument('--save_trajectory', type=str2bool, default=False,
                        help='Save trajectory')
    return parser.parse_args()


class YamlConfig:
    """Configuration class for managing directories"""
    def __init__(self, main_dir: str = None):
        if main_dir is None:
            self.MAIN_DIR = Path.cwd() / 'inputs'
        else:
            self.MAIN_DIR = Path(main_dir)
        self.PDB_DIR = self.MAIN_DIR / 'PDB'
        self.MSA_DIR = self.MAIN_DIR / 'MSA'
        self.YAML_DIR = self.MAIN_DIR / 'yaml'
    
    def setup_directories(self):
        """Create necessary directories if they don't exist."""
        for directory in [self.MAIN_DIR, self.PDB_DIR, self.MSA_DIR, self.YAML_DIR]:
            directory.mkdir(parents=True, exist_ok=True)


def load_boltz_model(args, device):
    """Load Boltz model"""
    predict_args = {
        "recycling_steps": args.recycling_steps,
        "sampling_steps": 200,
        "diffusion_samples": 1,
        "write_confidence_summary": True,
        "write_full_pae": False,
        "write_full_pde": False,
    }
    
    boltz_model = get_boltz_model(args.boltz_checkpoint, predict_args, device)
    boltz_model.train()
    return boltz_model, predict_args

def load_design_config(target_type, work_dir):
    """
    Load design configuration based on target type.
    Modified so that config files are always loaded from the script's directory,
    instead of using work_dir/boltzdesign/configs.
    """
    # Determine the directory where this script (boltzdesign.py) lives:
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # The configs directory is under script_dir/boltzdesign/configs/
    config_dir = os.path.join(script_dir, 'boltzdesign', 'configs')
    
    if target_type=='small_molecule':
        config_path = os.path.join(config_dir, "default_sm_config.yaml")
    elif target_type=='metal':
        config_path = os.path.join(config_dir, "default_metal_config.yaml")
    elif target_type=='dna' or target_type=='rna':
        config_path = os.path.join(config_dir, "default_na_config.yaml")

    elif target_type=='protein':
        config_path = os.path.join(config_dir, "default_ppi_config.yaml")
    else:
        raise ValueError(f"Unknown target type: {target_type}")
    
    print(f"Loading config from: {config_path}")
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    return config


def get_explicit_args():
    # Get all command-line arguments (excluding the script name)
    explicit_args = set()
    for arg in sys.argv[1:]:
        if arg.startswith('--'):
            # Handle --arg=value and --arg value
            if '=' in arg:
                explicit_args.add(arg.split('=')[0].lstrip('-').replace('-', '_'))
            else:
                explicit_args.add(arg.lstrip('-').replace('-', '_'))
    return explicit_args

def update_config_with_args(config, args):
    """Update configuration with command line arguments"""
    # Always update these basic parameters regardless of use_default_config
    basic_params = {
    'binder_chain': args.binder_id,
    'non_protein_target': args.target_type != 'protein',
    'pocket_conditioning': bool(args.contact_residues),
    }

    # Update basic parameters
    explicit_args = get_explicit_args()
    config.update(basic_params)
    
    # For advanced parameters, only update those that are explicitly set by the user
    # (i.e., different from their default values in argparse)
    parser = argparse.ArgumentParser()
    _, defaults = parser.parse_known_args([])  # Get default values
    
    advanced_params = {
        'mask_ligand': args.mask_ligand,
        'optimize_contact_per_binder_pos': args.optimize_contact_per_binder_pos,
        'distogram_only': args.distogram_only,
        'design_algorithm': args.design_algorithm,
        'learning_rate': args.learning_rate,
        'learning_rate_pre': args.learning_rate_pre,
        'e_soft': args.e_soft,
        'e_soft_1': args.e_soft_1,
        'e_soft_2': args.e_soft_2,
        'length_min': args.length_min,
        'length_max': args.length_max,
        'inter_chain_cutoff': args.inter_chain_cutoff,
        'intra_chain_cutoff': args.intra_chain_cutoff,
        'num_inter_contacts': args.num_inter_contacts,
        'num_intra_contacts': args.num_intra_contacts,
        'helix_loss_max': args.helix_loss_max,
        'helix_loss_min': args.helix_loss_min,
        'optimizer_type': args.optimizer_type,
        'pre_iteration': args.pre_iteration,
        'soft_iteration': args.soft_iteration,
        'temp_iteration': args.temp_iteration,
        'hard_iteration': args.hard_iteration,
        'semi_greedy_steps': args.semi_greedy_steps,
        'msa_max_seqs': args.msa_max_seqs,
        'recycling_steps': args.recycling_steps,
    }

    for param_name, param_value in advanced_params.items():
        if param_name in explicit_args:
            print(f"Updating {param_name} to {param_value}")
            config[param_name] = param_value
    return config
    
def run_boltz_design_step(args, config, boltz_model, yaml_dir, main_dir, version_name):
    """Run the Boltz design step"""
    print("Starting Boltz design step...")
    
    loss_scales = {
        'con_loss': args.con_loss,
        'i_con_loss': args.i_con_loss,
        'plddt_loss': args.plddt_loss,
        'pae_loss': args.pae_loss,
        'i_pae_loss': args.i_pae_loss,
        'rg_loss': args.rg_loss,
    }
    
    boltz_path = shutil.which("boltz")
    if boltz_path is None:
        raise FileNotFoundError("The 'boltz' command was not found in the system PATH.")
    
    run_boltz_design(
        boltz_path=boltz_path,
        main_dir=main_dir,
        yaml_dir=os.path.dirname(yaml_dir),
        boltz_model=boltz_model,
        ccd_path=args.ccd_path,
        design_samples=args.design_samples,
        version_name=version_name,
        config=config,
        loss_scales=loss_scales,
        show_animation=args.show_animation,
        save_trajectory=args.save_trajectory,
        redo_boltz_predict=args.redo_boltz_predict,
    )
    
    print("Boltz design step completed!")

def run_ligandmpnn_step(args, main_dir, version_name, ligandmpnn_dir, yaml_dir, work_dir):
    """Run the LigandMPNN redesign step"""
    print("Starting LigandMPNN redesign step...")
    # Setup LigandMPNN config
    yaml_path = f"{work_dir}/LigandMPNN/run_ligandmpnn_logits_config.yaml"
    with open(yaml_path, "r") as f:
        mpnn_config = yaml.safe_load(f)
    
    for key, value in mpnn_config.items():
        if isinstance(value, str) and "${CWD}" in value:
            mpnn_config[key] = value.replace("${CWD}", work_dir)
    
    if not Path(mpnn_config["checkpoint_soluble_mpnn"]).exists():
        raise FileNotFoundError("LigandMPNN checkpoint file not found!")
    
    with open(yaml_path, "w") as f:
        yaml.dump(mpnn_config, f, default_flow_style=False)
    
    # Setup directories
    boltzdesign_dir = f"{main_dir}/{version_name}/results_final"
    pdb_save_dir = f"{main_dir}/{version_name}/pdb"
    
    lmpnn_redesigned_dir = os.path.join(ligandmpnn_dir, '01_lmpnn_redesigned')
    lmpnn_redesigned_fa_dir = os.path.join(ligandmpnn_dir, '01_lmpnn_redesigned_fa')
    lmpnn_redesigned_yaml_dir = os.path.join(ligandmpnn_dir, '01_lmpnn_redesigned_yaml')
    
    os.makedirs(ligandmpnn_dir, exist_ok=True)
    # Convert CIF to PDB and run LigandMPNN
    convert_cif_files_to_pdb(boltzdesign_dir, pdb_save_dir, high_iptm=args.high_iptm, i_ptm_cutoff=args.i_ptm_cutoff)

    if not any(f.endswith('.pdb') for f in os.listdir(pdb_save_dir)):
        print("No successful designs from BoltzDesign")
        sys.exit(1)
    
    run_ligandmpnn_redesign(
        ligandmpnn_dir, pdb_save_dir, shutil.which("boltz"),
        os.path.dirname(yaml_dir), yaml_path, top_k=args.num_designs, cutoff=args.cutoff,
        non_protein_target=args.target_type != 'protein', binder_chain=args.binder_id,
        target_chains="all", out_dir=lmpnn_redesigned_fa_dir,
        lmpnn_yaml_dir=lmpnn_redesigned_yaml_dir, results_final_dir=lmpnn_redesigned_dir
    )
    
    # Filter high confidence designs
    filter_high_confidence_designs(args, ligandmpnn_dir, lmpnn_redesigned_dir, lmpnn_redesigned_yaml_dir)
    
    print("LigandMPNN redesign step completed!")
    return ligandmpnn_dir

def filter_high_confidence_designs(args, ligandmpnn_dir, lmpnn_redesigned_dir, lmpnn_redesigned_yaml_dir):
    """Filter and save high confidence designs"""
    print("Filtering high confidence designs...")
    
    yaml_dir_success_designs_dir = os.path.join(ligandmpnn_dir, '01_lmpnn_redesigned_high_iptm')
    yaml_dir_success_boltz_yaml = os.path.join(yaml_dir_success_designs_dir, 'yaml')
    yaml_dir_success_boltz_cif = os.path.join(yaml_dir_success_designs_dir, 'cif')
    
    os.makedirs(yaml_dir_success_boltz_yaml, exist_ok=True)
    os.makedirs(yaml_dir_success_boltz_cif, exist_ok=True)
    
    successful_designs = 0
    
    # Process designs
    for root in os.listdir(lmpnn_redesigned_dir):
        root_path = os.path.join(lmpnn_redesigned_dir, root, 'predictions')
        if not os.path.isdir(root_path):
            continue
        
        for subdir in os.listdir(root_path):
            json_path = os.path.join(root_path, subdir, f'confidence_{subdir}_model_0.json')
            yaml_path = os.path.join(lmpnn_redesigned_yaml_dir, f'{subdir}.yaml')
            cif_path = os.path.join(lmpnn_redesigned_dir, f'boltz_results_{subdir}', 'predictions', subdir, f'{subdir}_model_0.cif')
            
            try:
                with open(json_path, 'r') as f:
                    data = json.load(f)
                
                design_name = json_path.split('/')[-2]
                length = int(subdir[subdir.find('length') + 6:subdir.find('_model')])
                iptm = data.get('iptm', 0)
                complex_plddt = data.get('complex_plddt', 0)
                
                print(f"{design_name} length: {length} complex_plddt: {complex_plddt:.2f} iptm: {iptm:.2f}")
                
                if iptm > args.i_ptm_cutoff and complex_plddt > args.complex_plddt_cutoff:
                    shutil.copy(yaml_path, os.path.join(yaml_dir_success_boltz_yaml, f'{subdir}.yaml'))
                    shutil.copy(cif_path, os.path.join(yaml_dir_success_boltz_cif, f'{subdir}.cif'))
                    print(f"‚úÖ {design_name} copied")
                    successful_designs += 1
            
            except (KeyError, FileNotFoundError, json.JSONDecodeError) as e:
                print(f"Skipping {subdir}: {e}")
                continue
    
    if successful_designs == 0:
        print("Error: No LigandMPNN/ProteinMPNN redesigned designs passed the confidence thresholds")
        sys.exit(1)


def calculate_holo_apo_rmsd(af_pdb_dir, af_pdb_dir_apo, binder_chain):
    """Calculate RMSD between holo and apo structures and update confidence CSV.
    
    Args:
        af_pdb_dir (str): Directory containing holo PDB files
        af_pdb_dir_apo (str): Directory containing apo PDB files
    """
    confidence_csv_path = af_pdb_dir + '/high_iptm_confidence_scores.csv'
    if os.path.exists(confidence_csv_path):
        df_confidence_csv = pd.read_csv(confidence_csv_path)
        for pdb_name in os.listdir(af_pdb_dir):
            if pdb_name.endswith('.pdb'):
                pdb_path = os.path.join(af_pdb_dir, pdb_name)
                pdb_path_apo = os.path.join(af_pdb_dir_apo, pdb_name)
                xyz_holo, _ = get_CA_and_sequence(pdb_path, chain_id=binder_chain)
                xyz_apo, _ = get_CA_and_sequence(pdb_path_apo, chain_id='A')
                rmsd = np_rmsd(np.array(xyz_holo), np.array(xyz_apo))
                df_confidence_csv.loc[df_confidence_csv['file'] == pdb_name.split('.pdb')[0]+'.cif', 'rmsd'] = rmsd
                print(f"{pdb_path} rmsd: {rmsd}")
        df_confidence_csv.to_csv(confidence_csv_path, index=False)
        
        
def run_alphafold_step(args, ligandmpnn_dir, work_dir, mod_to_wt_aa):
    """Run AlphaFold validation step"""
    print("Starting AlphaFold validation step...")

    alphafold_dir = os.path.expanduser(args.alphafold_dir)
    afdb_dir = os.path.expanduser(args.af3_database_settings)
    hmmer_path = os.path.expanduser(args.af3_hmmer_path)
    print("alphafold_dir", alphafold_dir)
    print("afdb_dir", afdb_dir)
    print("hmmer_path", hmmer_path)
    
    # Create AlphaFold directories
    af_input_dir = f'{ligandmpnn_dir}/02_design_json_af3'
    af_output_dir = f'{ligandmpnn_dir}/02_design_final_af3'
    af_input_apo_dir = f'{ligandmpnn_dir}/02_design_json_af3_apo'
    af_output_apo_dir = f'{ligandmpnn_dir}/02_design_final_af3_apo'
    
    for dir_path in [af_input_dir, af_output_dir, af_input_apo_dir, af_output_apo_dir]:
        os.makedirs(dir_path, exist_ok=True)
    
    # Process YAML files
    yaml_dir_success_boltz_yaml = os.path.join(ligandmpnn_dir, '01_lmpnn_redesigned_high_iptm', 'yaml')
    
    process_yaml_files(
        yaml_dir_success_boltz_yaml,
        af_input_dir,
        af_input_apo_dir,
        target_type=args.target_type,
        binder_chain=args.binder_id,
        mod_to_wt_aa=mod_to_wt_aa,
        afdb_dir=afdb_dir,
        hmmer_path=hmmer_path
    )
    # Run AlphaFold on holo state
    subprocess.run([
        f'{work_dir}/boltzdesign/alphafold.sh',
        af_input_dir,
        af_output_dir,
        str(args.gpu_id),
        alphafold_dir,
        args.af3_docker_name
    ], check=True)
    
    # Run AlphaFold on apo state
    subprocess.run([
        f'{work_dir}/boltzdesign/alphafold.sh',
        af_input_apo_dir,
        af_output_apo_dir,
        str(args.gpu_id),
        alphafold_dir,
        args.af3_docker_name
    ], check=True)
    
    print("AlphaFold validation step completed!")

    af_pdb_dir = f"{ligandmpnn_dir}/03_af_pdb_success"
    af_pdb_dir_apo = f"{ligandmpnn_dir}/03_af_pdb_apo"
    
    convert_cif_files_to_pdb(af_output_dir, af_pdb_dir, af_dir=True, high_iptm=args.high_iptm)
    if not any(f.endswith('.pdb') for f in os.listdir(af_pdb_dir)):
        print("No successful designs from AlphaFold")
        sys.exit(1)
    convert_cif_files_to_pdb(af_output_apo_dir, af_pdb_dir_apo, af_dir=True)
    calculate_holo_apo_rmsd(af_pdb_dir, af_pdb_dir_apo, args.binder_id)

    return af_output_dir, af_output_apo_dir, af_pdb_dir, af_pdb_dir_apo

def run_rosetta_step(args, ligandmpnn_dir, af_output_dir, af_output_apo_dir, af_pdb_dir, af_pdb_dir_apo):
    """Run Rosetta energy calculation (protein targets only)"""
    if args.target_type != 'protein':
        print("Skipping Rosetta step (not a protein target)")
        return
    
    print("Starting Rosetta energy calculation...")
    af_pdb_rosetta_success_dir = f"{ligandmpnn_dir}/af_pdb_rosetta_success"
    from pyrosetta_utils import measure_rosetta_energy
    measure_rosetta_energy(
        af_pdb_dir, af_pdb_dir_apo, af_pdb_rosetta_success_dir,
        binder_holo_chain=args.binder_id, binder_apo_chain='A'
    )
    
    print("Rosetta energy calculation completed!")

def setup_environment():
    """Setup environment and parse arguments"""
    args = parse_arguments()
    work_dir = args.work_dir or os.getcwd()
    os.chdir(work_dir)
    setup_gpu_environment(args.gpu_id)
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    return args

def get_target_ids(args):
    """Get target IDs from either PDB or custom input"""
    target_ids = args.pdb_target_ids if args.input_type == "pdb" else args.custom_target_ids
    
    if (args.contact_residues or args.modifications) and not target_ids:
        input_type = "PDB" if args.input_type == "pdb" else "Custom"
        raise ValueError(f"{input_type} target IDs must be provided when using contacts or modifications")
        sys.exit(1)

    return [str(x.strip()) for x in target_ids.split(",")] if target_ids else []

def assign_chain_ids(target_ids_list, binder_chain='A'):
    """Maps target IDs to unique chain IDs, skipping binder_chain."""
    letters = [c for c in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' if c != binder_chain]
    return {id: letters[i] for i, id in enumerate(target_ids_list)}


def initialize_pipeline(args):
    """Initialize models and configurations"""
    work_dir = args.work_dir or os.getcwd()
    boltz_model, _ = load_boltz_model(args, torch.device("cuda:0" if torch.cuda.is_available() else "cpu"))
    
    config_obj = YamlConfig(main_dir=f'{work_dir}/inputs/{args.target_type}_{args.target_name}_{args.suffix}')
    config_obj.setup_directories()
    return boltz_model, config_obj

def generate_yaml_config(args, config_obj):
    """Generate YAML configuration based on input type"""
    if args.contact_residues or args.modifications:
        target_ids_list = get_target_ids(args)
        target_id_map = assign_chain_ids(target_ids_list, args.binder_id)
        print(f"Mapped target IDs: {list(target_id_map.values())}")
        constraints, modifications = process_design_constraints(target_id_map, args.modifications, args.modifications_positions, args.modification_target, args.contact_residues, args.constraint_target, args.binder_id)
    else:
        constraints, modifications = None, None
    target = []
    if args.input_type == "pdb":
        pdb_target_ids = [str(x.strip()) for x in args.pdb_target_ids.split(",")] if args.pdb_target_ids else None
        target_mols = [str(x.strip()) for x in args.target_mols.split(",")] if args.target_mols else None
        if args.pdb_path:
            pdb_path = Path(args.pdb_path)
            print("load local pdb from", pdb_path)
            if not pdb_path.is_file():
                raise FileNotFoundError(f"Could not find local PDB: {args.pdb_path}")
        else:
            print("fetch pdb from RCSB")
            download_pdb(args.target_name, config_obj.PDB_DIR)
            pdb_path = config_obj.PDB_DIR / f"{args.target_name}.pdb"

        if args.target_type in ['rna', 'dna']:
            nucleotide_dict = get_nucleotide_from_pdb(pdb_path)
            for target_id in pdb_target_ids:
                target.append(nucleotide_dict[target_id]['seq'])
        elif args.target_type == 'small_molecule':
            ligand_dict = get_ligand_from_pdb(args.target_name)
            for target_mol in target_mols:
                print(target_mol, ligand_dict.keys())
                target.append(ligand_dict[target_mol])
        elif args.target_type == 'protein':
            chain_sequences = get_chains_sequence(pdb_path)
            for target_id in pdb_target_ids:
                target.append(chain_sequences[target_id])
        else:
            raise ValueError(f"Unsupported target type: {args.target_type}")
    else:
        target_inputs = [str(x.strip()) for x in args.custom_target_input.split(",")] if args.custom_target_input else []
        target = target_inputs or [args.target_name]

    return generate_yaml_for_target_binder(
        args.target_name, 
        args.target_type,
        target,
        config=config_obj,
        binder_id=args.binder_id,
        constraints=constraints,
        modifications=modifications['data'] if modifications else None,
        modification_target=modifications['target'] if modifications else None,
        use_msa=args.use_msa
    )

def setup_pipeline_config(args):
    """Setup pipeline configuration"""
    work_dir = args.work_dir or os.getcwd()
    config = load_design_config(args.target_type, work_dir)
    return update_config_with_args(config, args)

def setup_output_directories(args):
    """Setup output directories"""
    work_dir = args.work_dir or os.getcwd()
    main_dir = f'{work_dir}/outputs'
    os.makedirs(main_dir, exist_ok=True)
    return {
        'main_dir': main_dir,
        'version': f'{args.target_type}_{args.target_name}_{args.suffix}'
    }
def modification_to_wt_aa(modifications, modifications_wt):
    """Convert modifications to WT AA"""
    if not modifications:
        return None, None
    mod_to_wt_aa = {}
    for mod, wt in zip(modifications.split(','), modifications_wt.split(',')):
        mod_to_wt_aa[mod] = wt
    return mod_to_wt_aa

def run_pipeline_steps(args, config, boltz_model, yaml_dir, output_dir):
    """Run the pipeline steps based on arguments"""
    results = {'ligandmpnn_dir': f"{output_dir['main_dir']}/{output_dir['version']}/ligandmpnn_cutoff_{args.cutoff}", 'af_output_dir': None, 'af_output_apo_dir': None, 'af_pdb_dir': None, 'af_pdb_dir_apo': None}
    
    if args.run_boltz_design:
        run_boltz_design_step(args, config, boltz_model, yaml_dir, 
                            output_dir['main_dir'], output_dir['version'])

    if args.run_ligandmpnn:
        run_ligandmpnn_step(
            args, output_dir['main_dir'], output_dir['version'], 
            results['ligandmpnn_dir'], yaml_dir, args.work_dir or os.getcwd()
        )
    if args.run_alphafold:
        mod_to_wt_aa = modification_to_wt_aa(args.modifications, args.modifications_wt)
        results['af_output_dir'], results['af_output_apo_dir'], results['af_pdb_dir'], results['af_pdb_dir_apo'] = run_alphafold_step(
            args, results['ligandmpnn_dir'], args.work_dir or os.getcwd(), mod_to_wt_aa
        )
    
    if args.run_rosetta:
        run_rosetta_step(args, results['ligandmpnn_dir'], 
                        results['af_output_dir'], results['af_output_apo_dir'], results['af_pdb_dir'], results['af_pdb_dir_apo'])
    
    return results

def main():
    """Main function for running the BoltzDesign pipeline"""
    args = setup_environment()
    
    # Ê£ÄÊü•ËÆæËÆ°Ê®°ÂºèÂπ∂ÊâßË°åÁõ∏Â∫îÁöÑÊµÅÁ®ã
    if args.design_mode == 'aptamer':
        run_aptamer_design_pipeline(args)
        return
    elif args.design_mode == 'predict_structure' or args.predict_structure_only:
        run_aptamer_structure_prediction_only(args)
        return
    
    # ÂéüÊúâÁöÑËõãÁôΩË¥®ËÆæËÆ°ÊµÅÁ®ã
    boltz_model, config_obj = initialize_pipeline(args)
    yaml_dict, yaml_dir = generate_yaml_config(args, config_obj)

    print("Generated YAML configuration:")
    for key, value in yaml_dict.items():
        if isinstance(value, list):
            print(f"  {key}:")
            for item in value:
                print(f"    - {item}")
        else:
            print(f"  {key}: {value}")
    
    # Setup pipeline configuration
    config = setup_pipeline_config(args)
    output_dir = setup_output_directories(args)
    
    # Run pipeline steps
    print("config:")
    items = list(config.items())
    max_key_len = max(len(key) for key, _ in items)
    max_val_len = max(len(str(val)) for _, val in items)
    
    # Print header
    print("  " + "=" * (max_key_len + max_val_len + 5))
    
    # Print items in two columns
    for i in range(0, len(items), 2):
        key1, value1 = items[i]
        if i+1 < len(items):
            key2, value2 = items[i+1]
            print(f"  {key1:<{max_key_len}}: {str(value1):<{max_val_len}}    "
                  f"{key2:<{max_key_len}}: {value2}")
        else:
            print(f"  {key1:<{max_key_len}}: {value1}")
    
    print("  " + "=" * (max_key_len + max_val_len + 5))
    results = run_pipeline_steps(args, config, boltz_model, yaml_dir, output_dir)
    
    print("Pipeline completed successfully!")


def run_aptamer_design_pipeline(args):
    """ËøêË°åÈÄÇÈÖç‰ΩìËÆæËÆ°ÊµÅÁ®ã - ÂÆûÁé∞ËßíËâ≤‰∫íÊç¢ÁöÑÊ†∏ÂøÉÈÄªËæë"""
    print("üß¨" + "="*80)
    print(f"üöÄ ÂêØÂä® {args.aptamer_type} ÈÄÇÈÖç‰ΩìËÆæËÆ°ÊµÅÁ®ã")
    print("üß¨" + "="*80)
    
    # È™åËØÅÂøÖË¶ÅÂèÇÊï∞
    if not args.target_protein_seq and not args.target_ligand_smiles:
        print("‚ùå ÈîôËØØ: ÈÄÇÈÖç‰ΩìËÆæËÆ°Ê®°ÂºèÈúÄË¶ÅÁõÆÊ†áËõãÁôΩË¥®Â∫èÂàó (--target_protein_seq) ÊàñÂ∞èÂàÜÂ≠êSMILES (--target_ligand_smiles)")
        return
    
    if args.target_protein_seq and args.target_ligand_smiles:
        print("‚ùå ÈîôËØØ: ËØ∑ÈÄâÊã©‰∏Ä‰∏™ÁõÆÊ†áÁ±ªÂûãÔºöËõãÁôΩË¥®Â∫èÂàóÊàñÂ∞èÂàÜÂ≠êSMILESÔºå‰∏çËÉΩÂêåÊó∂ÊåáÂÆö‰∏§ËÄÖ")
        return
    
    if args.aptamer_length < 20 or args.aptamer_length > 80:
        print("‚ö†Ô∏è  Ë≠¶Âëä: ÈÄÇÈÖç‰ΩìÈïøÂ∫¶Âª∫ËÆÆÂú®20-80‰πãÈó¥")
    
    # ËÆæÁΩÆÁéØÂ¢É
    setup_gpu_environment(args.gpu_id)
    print(f"üñ•Ô∏è  ‰ΩøÁî®GPU: {args.gpu_id}")
    
    # ÂàùÂßãÂåñÊ®°Âûã
    sys.path.append(f'{os.getcwd()}/boltzdesign')
    from boltzdesign_utils import get_boltz_model
    from aptamer_design_utils import AptamerDesignConfig, create_aptamer_yaml, save_aptamer_yaml
    
    # Âä†ËΩΩÊ®°Âûã
    cache_dir = os.path.expanduser("~/.boltz")
    checkpoint_path = '/home/zihao/.boltz/boltz1_conf.ckpt'
    if not os.path.exists(checkpoint_path):
        print(f"‚ùå ÈîôËØØ: Êâæ‰∏çÂà∞BoltzÊ®°ÂûãÊùÉÈáçÊñá‰ª∂: {checkpoint_path}")
        print("ËØ∑ËøêË°å: python -c 'from boltz.main import download; from pathlib import Path; download(Path(\"~/.boltz\").expanduser())'")
        return
    
    device = f"cuda:{args.gpu_id}" if torch.cuda.is_available() else "cpu"
    boltz_model = get_boltz_model(checkpoint_path, device=device)
    print(f"‚úÖ BoltzÊ®°ÂûãÂä†ËΩΩÊàêÂäü")
    
    # ÂàõÂª∫ÈÄÇÈÖç‰ΩìÈÖçÁΩÆ
    if args.target_protein_seq:
        target_chains = args.target_protein_chains.split(',') if args.target_protein_chains else ['B']
        target_type = 'protein'
    else:
        target_chains = args.target_ligand_chains.split(',') if args.target_ligand_chains else ['B']
        target_type = 'ligand'
    
    aptamer_config = AptamerDesignConfig(
        aptamer_type=args.aptamer_type,
        aptamer_chain=args.aptamer_chain, 
        target_chains=target_chains,
        target_type=target_type
    )
    print(f"üîß ÈÄÇÈÖç‰ΩìÈÖçÁΩÆ: {args.aptamer_type} ÈÄÇÈÖç‰ΩìÈìæ {args.aptamer_chain} -> ËõãÁôΩË¥®Èìæ {target_chains}")
    
    # ÂàõÂª∫ÈÄÇÈÖç‰ΩìËÆæËÆ°YAML (Ê†πÊçÆÁõÆÊ†áÁ±ªÂûãÈÄâÊã©)
    if args.target_protein_seq:
        from aptamer_design_utils import create_aptamer_yaml
        yaml_content = create_aptamer_yaml(args.target_protein_seq, aptamer_config, f"{args.aptamer_type.lower()}_aptamer_{args.target_name}")
        target_info = f"ËõãÁôΩË¥®Â∫èÂàó: {args.target_protein_seq[:30]}{'...' if len(args.target_protein_seq) > 30 else ''}"
    else:
        from aptamer_design_utils import create_ligand_aptamer_yaml
        yaml_content = create_ligand_aptamer_yaml(args.target_ligand_smiles, aptamer_config, f"{args.aptamer_type.lower()}_ligand_aptamer_{args.target_name}")
        target_info = f"Â∞èÂàÜÂ≠êSMILES: {args.target_ligand_smiles[:50]}{'...' if len(args.target_ligand_smiles) > 50 else ''}"
    
    # ‰øùÂ≠òYAMLÊñá‰ª∂
    work_dir = args.work_dir or os.getcwd()
    output_dir = f'{work_dir}/outputs/aptamer_{args.aptamer_type.lower()}_{args.target_name}_{args.suffix}'
    os.makedirs(output_dir, exist_ok=True)
    yaml_path = save_aptamer_yaml(yaml_content, f"{output_dir}/aptamer_design.yaml")
    print(f"üìù YAMLÈÖçÁΩÆÂ∑≤‰øùÂ≠ò: {yaml_path}")
    
    # Âä†ËΩΩCCDÂ∫ì
    import pickle
    ccd_path = '/home/zihao/.boltz/ccd.pkl'
    with open(ccd_path, 'rb') as f:
        ccd_lib = pickle.load(f)
    
    # Âä†ËΩΩÈÄÇÈÖç‰ΩìÈÖçÁΩÆ
    config_path = f'boltzdesign/configs/aptamer_{args.aptamer_type.lower()}_config.yaml'
    with open(config_path, 'r') as f:
        design_config = yaml.safe_load(f)
    
    # Êõ¥Êñ∞ÈÖçÁΩÆÂèÇÊï∞ (ÁßªÈô§‰∏éÂáΩÊï∞ÂèÇÊï∞ÂÜ≤Á™ÅÁöÑÈîÆ)
    conflicting_keys = ['length', 'aptamer_type', 'aptamer_chain', 'target_chains', 'length_min', 'length_max', 'gc_content_target', 'gc_content_weight']
    for key in conflicting_keys:
        design_config.pop(key, None)
    chain_to_number = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}
    
    print("üöÄ ÂºÄÂßãÈÄÇÈÖç‰ΩìËÆæËÆ°‰ºòÂåñ...")
    print(f"üéØ ÁõÆÊ†á: ËÆæËÆ°ÈïøÂ∫¶‰∏∫ {args.aptamer_length} ÁöÑ {args.aptamer_type} ÈÄÇÈÖç‰Ωì")
    print(f"üß™ ÁõÆÊ†á‰ø°ÊÅØ: {target_info}")
    
    try:
        # ËøêË°åÈÄÇÈÖç‰ΩìËÆæËÆ° (Ê†∏ÂøÉÁöÑËßíËâ≤‰∫íÊç¢ÈÄªËæë)
        from boltzdesign_utils import boltz_hallucination
        
        result = boltz_hallucination(
            boltz_model=boltz_model,
            yaml_path=yaml_path,
            ccd_lib=ccd_lib,
            length=args.aptamer_length,
            binder_chain=aptamer_config.aptamer_chain,
            aptamer_config=aptamer_config,  # Êñ∞Â¢û: ÊøÄÊ¥ªÈÄÇÈÖç‰ΩìÊ®°Âºè
            chain_to_number=chain_to_number,
            **design_config
        )
        
        print("‚úÖ ÈÄÇÈÖç‰ΩìËÆæËÆ°ÂÆåÊàê!")
        print(f"üìÅ ÁªìÊûú‰øùÂ≠òÂú®: {output_dir}")
        
        # ÊèêÂèñÊúÄÁªàÂ∫èÂàó
        from aptamer_design_utils import validate_aptamer_design
        
        # ‰ªéYAML‰∏≠ËØªÂèñÊúÄÁªàÂ∫èÂàó
        with open(yaml_path, 'r') as f:
            final_yaml = yaml.safe_load(f)
        
        final_sequence = None
        for seq_entry in final_yaml['sequences']:
            if args.aptamer_type.lower() in seq_entry:
                final_sequence = seq_entry[args.aptamer_type.lower()]['sequence']
                break
        
        if final_sequence:
            validation = validate_aptamer_design(final_sequence, args.aptamer_type)
            print(f"üéØ ÊúÄÁªàÈÄÇÈÖç‰ΩìÂ∫èÂàó: {final_sequence}")
            print(f"üìä Â∫èÂàóÈïøÂ∫¶: {validation['length']}")
            print(f"üìä GCÂê´Èáè: {validation['gc_content']:.2%}")
            if args.target_protein_seq:
                print(f"üß™ ÁõÆÊ†áËõãÁôΩË¥®Â∫èÂàó: {args.target_protein_seq}")
                print(f"üîó ËõãÁôΩË¥®ÈïøÂ∫¶: {len(args.target_protein_seq)} Ê∞®Âü∫ÈÖ∏")
            else:
                print(f"üß™ ÁõÆÊ†áÂ∞èÂàÜÂ≠êSMILES: {args.target_ligand_smiles}")
                print(f"üîó Â∞èÂàÜÂ≠êÂ§çÊùÇÂ∫¶: {len(args.target_ligand_smiles)} Â≠óÁ¨¶")

            # ËøêË°åÁªìÊûÑÈ¢ÑÊµãÂíå‰øùÂ≠ò
            # ËøêË°åÁªìÊûÑÈ¢ÑÊµãÂíå‰øùÂ≠ò
            if args.save_structures:
                print("\nüèóÔ∏è ÂºÄÂßãÁîüÊàêÊúÄÁªà‰∏âÁª¥ÁªìÊûÑ...")
                try:
                    structure_results = run_aptamer_structure_prediction(
                        args, yaml_path, output_dir, None, final_sequence
                    )
                    print(f"\n‚úÖ ÁªìÊûÑÈ¢ÑÊµãÂÆåÊàê! Êñá‰ª∂‰øùÂ≠òÂú®: {structure_results['structure_dir']}")
                    
                    # ÊòæÁ§∫ÁîüÊàêÁöÑÊñá‰ª∂
                    print("\nüìã ÁîüÊàêÁöÑÊñá‰ª∂:")
                    for file_type, file_path in structure_results['files'].items():
                        if file_path and os.path.exists(file_path):
                            file_size = os.path.getsize(file_path) / 1024
                            print(f"üìÅ {file_type.upper()}: {file_path} ({file_size:.1f} KB)")
                    
                    # ÊòæÁ§∫ËØ¶ÁªÜÁöÑÁªìÊûÑË¥®Èáè‰ø°ÊÅØ
                    if 'confidence' in structure_results:
                        conf = structure_results['confidence']
                        print(f"\nüìä ÁªìÊûÑÁΩÆ‰ø°Â∫¶ÊåáÊ†á:")
                        print(f"  ‚Ä¢ pLDDT (Â±ÄÈÉ®Ë¥®Èáè): {conf['avg_plddt']:.3f}")
                        print(f"  ‚Ä¢ iPTM (ÈìæÈó¥Êé•Ëß¶): {conf['iptm']:.3f} ‚≠êÂÖ≥ÈîÆÊåáÊ†á")
                        print(f"  ‚Ä¢ pTM (Êï¥‰ΩìÂØπÈΩê): {conf['ptm']:.3f}")
                        print(f"  ‚Ä¢ iPAE (ÈìæÈó¥ËØØÂ∑Æ): {conf['ipae']:.2f}√Ö ‚≠êÂÖ≥ÈîÆÊåáÊ†á")
                        
                        # ÁªºÂêàËØÑÁ∫ß
                        if 'evaluation' in structure_results and 'final_score' in structure_results['evaluation']:
                            eval_result = structure_results['evaluation']
                            print(f"\nüéØ ÁªºÂêàË¥®ÈáèËØÑÂàÜ: {eval_result['final_score']:.1f}/100")
                            print(f"üìã ËØÑÁ∫ß: {eval_result['grade']}")
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è ÁªìÊûÑÈ¢ÑÊµãËøáÁ®ã‰∏≠Âá∫Áé∞ÈîôËØØ: {str(e)}")
                    print("üí° Â∫èÂàóËÆæËÆ°Â∑≤ÂÆåÊàêÔºå‰ΩÜÁªìÊûÑÁîüÊàêÂ§±Ë¥•")
        
    except Exception as e:
        print(f"‚ùå ÈÄÇÈÖç‰ΩìËÆæËÆ°ËøáÁ®ã‰∏≠Âá∫Áé∞ÈîôËØØ: {str(e)}")
        import traceback
        print("ËØ¶ÁªÜÈîôËØØ‰ø°ÊÅØ:")
        traceback.print_exc()

# ============================================================================
# Âú® boltzdesign1.py ‰∏≠Ê∑ªÂä†/‰øÆÊîπ‰ª•‰∏ãÂáΩÊï∞
# ============================================================================

def evaluate_aptamer_comprehensive(confidence_file, sequence, aptamer_type, cif_file=None):
    """
    ÁªºÂêàËØÑ‰º∞RNA/DNAÈÄÇÈÖç‰ΩìËÆæËÆ°Ë¥®Èáè
    
    ËØÑ‰º∞Áª¥Â∫¶Ôºö
    1. ÁªìÊûÑÁΩÆ‰ø°Â∫¶ (pLDDT, iPTM, iPAE) - 50%ÊùÉÈáç
    2. ‰∫åÁ∫ßÁªìÊûÑ (RNAfold MFE) - 30%ÊùÉÈáç
    3. Â∫èÂàóË¥®Èáè - 20%ÊùÉÈáç
    
    Args:
        confidence_file: ÁΩÆ‰ø°Â∫¶JSONÊñá‰ª∂Ë∑ØÂæÑ
        sequence: ÈÄÇÈÖç‰ΩìÂ∫èÂàó
        aptamer_type: 'RNA' Êàñ 'DNA'
        cif_file: CIFÁªìÊûÑÊñá‰ª∂ÔºàÂèØÈÄâÔºåÁî®‰∫éÈ¢ùÂ§ñÈ™åËØÅÔºâ
    
    Returns:
        dict: ËØÑ‰º∞ÁªìÊûúÂ≠óÂÖ∏
    """
    import json
    import re
    import subprocess
    from collections import Counter
    import math
    
    print(f"\n{'='*80}")
    print(f"üß¨ {aptamer_type}ÈÄÇÈÖç‰ΩìËÆæËÆ°Ë¥®ÈáèÁªºÂêàËØÑ‰º∞")
    print(f"{'='*80}\n")
    
    results = {
        'scores': {},
        'metrics': {},
        'recommendations': []
    }
    
    # ===== 1. ÁªìÊûÑÁΩÆ‰ø°Â∫¶ÊåáÊ†á (ÊúÄÈáçË¶Å!) =====
    print(f"üìä 1. ÁªìÊûÑÈ¢ÑÊµãÁΩÆ‰ø°Â∫¶ËØÑ‰º∞")
    
    try:
        with open(confidence_file, 'r') as f:
            conf = json.load(f)
        
        # pLDDT (Â±ÄÈÉ®ÁªìÊûÑË¥®Èáè)
        plddt = conf.get('complex_plddt', 0.0)
        plddt_score = plddt * 100
        plddt_grade = "‚úÖ‰ºòÁßÄ" if plddt > 0.7 else "‚ö†Ô∏è‰∏≠Á≠â" if plddt > 0.5 else "‚ùå‰Ωé"
        results['metrics']['plddt'] = plddt
        print(f"   ‚Ä¢ pLDDT (Â±ÄÈÉ®ÁªìÊûÑË¥®Èáè): {plddt:.3f} {plddt_grade}")
        print(f"     ‚îî‚îÄ ÂèÇËÄÉÊÑè‰πâ: ÂØπRNA/DNAÁöÑÁΩÆ‰ø°Â∫¶È¢ÑÊµãÊúâÈôêÔºå‰ªÖ‰ΩúÂèÇËÄÉ")
        
        # iPTM (ÈìæÈó¥Êé•Ëß¶Ë¥®Èáè - ÂÖ≥ÈîÆÊåáÊ†á!)
        iptm = conf.get('iptm', 0.0)
        iptm_score = max(0, min(100, (iptm - 0.3) / 0.4 * 100))  # 0.3-0.7Êò†Â∞ÑÂà∞0-100
        iptm_grade = "‚úÖ‰ºòÁßÄ" if iptm > 0.6 else "‚ö†Ô∏è‰∏≠Á≠â" if iptm > 0.4 else "‚ùå‰Ωé"
        results['metrics']['iptm'] = iptm
        print(f"   ‚Ä¢ iPTM (ÈìæÈó¥Êé•Ëß¶Ë¥®Èáè): {iptm:.3f} {iptm_grade} ‚≠ê‰∏ªË¶ÅÊåáÊ†á")
        print(f"     ‚îî‚îÄ ËØÑ‰º∞ÈÄÇÈÖç‰Ωì‰∏éËõãÁôΩË¥®ÁöÑÁªìÂêàÂº∫Â∫¶ (>0.6‰ºòÁßÄ, >0.4ÂèØÊé•Âèó)")
        
        # pTM (Êï¥‰ΩìÂØπÈΩêË¥®Èáè)
        ptm = conf.get('ptm', 0.0)
        ptm_score = max(0, min(100, (ptm - 0.3) / 0.4 * 100))
        results['metrics']['ptm'] = ptm
        print(f"   ‚Ä¢ pTM (Êï¥‰ΩìÂØπÈΩêË¥®Èáè): {ptm:.3f}")
        
        # iPAE (ÈìæÈó¥Ë∑ùÁ¶ªËØØÂ∑Æ - ÂÖ≥ÈîÆÊåáÊ†á!)
        # ‰ªépair_chains_iptm‰∏≠ÊèêÂèñÈìæÈó¥pAE‰ø°ÊÅØ
        ipae_value = None
        if 'pair_chains_iptm' in conf:
            # Â∞ùËØïÊèêÂèñÈìæÈó¥ÁöÑpAE‰ø°ÊÅØÔºàÂ¶ÇÊûúÊúâÁöÑËØùÔºâ
            # Ê≥®ÊÑèÔºöconfidenceÊñá‰ª∂ÂèØËÉΩ‰∏çÁõ¥Êé•ÂåÖÂê´ipAEÔºå‰ΩÜÂèØ‰ª•‰ªéiptmÊé®ÁÆó
            # ÈÄöÂ∏∏ ipAE ‚âà (1 - iptm) * 31.0
            ipae_value = (1 - iptm) * 31.0 if iptm > 0 else 31.0
        
        if ipae_value is not None:
            ipae_score = max(0, 100 - ipae_value * 5)  # <10√ÖÂæóÈ´òÂàÜ
            ipae_grade = "‚úÖ‰ºòÁßÄ" if ipae_value < 10 else "‚ö†Ô∏è‰∏≠Á≠â" if ipae_value < 15 else "‚ùåÈ´ò"
            results['metrics']['ipae'] = ipae_value
            print(f"   ‚Ä¢ iPAE (ÈìæÈó¥Ë∑ùÁ¶ªËØØÂ∑Æ): {ipae_value:.2f}√Ö {ipae_grade} ‚≠ê‰∏ªË¶ÅÊåáÊ†á")
            print(f"     ‚îî‚îÄ È¢ÑÊµãÁöÑÈìæÈó¥ÂéüÂ≠êË∑ùÁ¶ªËØØÂ∑Æ (<10√Ö‰ºòÁßÄ, <15√ÖÂèØÊé•Âèó)")
        else:
            ipae_score = 50  # ÈªòËÆ§‰∏≠Á≠âÂàÜ
            print(f"   ‚Ä¢ iPAE (ÈìæÈó¥Ë∑ùÁ¶ªËØØÂ∑Æ): Êú™Êèê‰æõ")
        
        # ËÆ°ÁÆóÁªìÊûÑÁΩÆ‰ø°Â∫¶ÊÄªÂàÜ (iPTMÂíåiPAEÊùÉÈáçÊúÄÈ´ò)
        structure_conf_score = (
            iptm_score * 0.45 +      # iPTM 45%
            ipae_score * 0.30 +      # iPAE 30%
            ptm_score * 0.15 +       # pTM 15%
            plddt_score * 0.10       # pLDDT 10%
        )
        results['scores']['structure_confidence'] = structure_conf_score
        
        print(f"\n   üìà ÁªìÊûÑÁΩÆ‰ø°Â∫¶ÂæóÂàÜ: {structure_conf_score:.1f}/100")
        print(f"      (iPTM 45% + iPAE 30% + pTM 15% + pLDDT 10%)")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è ËØªÂèñÁΩÆ‰ø°Â∫¶Êñá‰ª∂Â§±Ë¥•: {e}")
        structure_conf_score = 0
        results['scores']['structure_confidence'] = 0
    
    # ===== 2. RNA/DNA‰∫åÁ∫ßÁªìÊûÑÈ¢ÑÊµã =====
    print(f"\nüß¨ 2. {aptamer_type}‰∫åÁ∫ßÁªìÊûÑÈ¢ÑÊµã (ViennaRNA)")
    
    try:
        # Ê£ÄÊü•RNAfoldÊòØÂê¶ÂèØÁî®
        result = subprocess.run(['which', 'RNAfold'], 
                              capture_output=True, text=True, timeout=5)
        
        if result.returncode == 0:
            # ËøêË°åRNAfold
            process = subprocess.Popen(['RNAfold', '--noPS'], 
                                     stdin=subprocess.PIPE,
                                     stdout=subprocess.PIPE,
                                     stderr=subprocess.PIPE,
                                     text=True)
            
            stdout, stderr = process.communicate(input=sequence, timeout=30)
            
            # Ëß£ÊûêËæìÂá∫
            lines = stdout.strip().split('\n')
            if len(lines) >= 2:
                structure_line = lines[1]
                match = re.search(r'\(([-\d.]+)\)', structure_line)
                
                if match:
                    mfe = float(match.group(1))
                    
                    # MFEËØÑÂàÜ
                    if mfe < -25:
                        mfe_grade = "‚úÖ‰ºòÁßÄ(ÈùûÂ∏∏Á®≥ÂÆö)"
                        mfe_score = 100
                    elif mfe < -15:
                        mfe_grade = "‚úÖËâØÂ•Ω(Á®≥ÂÆö)"
                        mfe_score = 85
                    elif mfe < -8:
                        mfe_grade = "‚ö†Ô∏è‰∏≠Á≠â(ËæÉÁ®≥ÂÆö)"
                        mfe_score = 65
                    else:
                        mfe_grade = "‚ùå‰∏çÁ®≥ÂÆö"
                        mfe_score = 35
                    
                    results['metrics']['mfe'] = mfe
                    print(f"   ‚Ä¢ ÊúÄÂ∞èËá™Áî±ËÉΩ(MFE): {mfe:.2f} kcal/mol {mfe_grade}")
                    print(f"     ‚îî‚îÄ ÁÉ≠ÂäõÂ≠¶Á®≥ÂÆöÊÄß (<-15 kcal/mol ‰∏∫Á®≥ÂÆö)")
                    
                    # ‰∫åÁ∫ßÁªìÊûÑ
                    structure = structure_line.split()[0]
                    paired = structure.count('(') + structure.count(')')
                    pairing_ratio = paired / len(structure)
                    
                    results['metrics']['secondary_structure'] = structure
                    results['metrics']['pairing_ratio'] = pairing_ratio
                    
                    if pairing_ratio > 0.5:
                        pairing_grade = "‚úÖÈ´òÈÖçÂØπÁéá"
                        pairing_score = 100
                    elif pairing_ratio > 0.3:
                        pairing_grade = "‚ö†Ô∏è‰∏≠Á≠âÈÖçÂØπÁéá"
                        pairing_score = 70
                    else:
                        pairing_grade = "‚ùå‰ΩéÈÖçÂØπÁéá"
                        pairing_score = 40
                    
                    print(f"   ‚Ä¢ ‰∫åÁ∫ßÁªìÊûÑ: {structure}")
                    print(f"   ‚Ä¢ Á¢±Âü∫ÈÖçÂØπÁéá: {pairing_ratio*100:.1f}% ({paired}/{len(sequence)}) {pairing_grade}")
                    
                    secondary_structure_score = (mfe_score + pairing_score) / 2
                    
                else:
                    print(f"   ‚ö†Ô∏è Êó†Ê≥ïËß£ÊûêRNAfoldËæìÂá∫")
                    secondary_structure_score = 50
            else:
                print(f"   ‚ö†Ô∏è RNAfoldËæìÂá∫Ê†ºÂºèÂºÇÂ∏∏")
                secondary_structure_score = 50
                
        else:
            print(f"   ‚ö†Ô∏è RNAfoldÊú™ÂÆâË£ÖÔºåË∑≥Ëøá‰∫åÁ∫ßÁªìÊûÑÈ¢ÑÊµã")
            print(f"   üí° ÂÆâË£Ö: conda install -c bioconda viennarna")
            secondary_structure_score = 50
            
    except subprocess.TimeoutExpired:
        print(f"   ‚ö†Ô∏è RNAfoldÊâßË°åË∂ÖÊó∂")
        secondary_structure_score = 50
    except Exception as e:
        print(f"   ‚ö†Ô∏è RNAfoldÊâßË°åÂ§±Ë¥•: {e}")
        secondary_structure_score = 50
    
    results['scores']['secondary_structure'] = secondary_structure_score
    print(f"\n   üìà ‰∫åÁ∫ßÁªìÊûÑÂæóÂàÜ: {secondary_structure_score:.1f}/100")
    
    # ===== 3. Â∫èÂàóË¥®ÈáèËØÑ‰º∞ =====
    print(f"\nüìù 3. Â∫èÂàóË¥®ÈáèËØÑ‰º∞")
    
    # NÂê´Èáè
    n_count = sequence.count('N')
    n_ratio = n_count / len(sequence)
    n_score = max(0, 100 - n_ratio * 200)
    results['metrics']['n_content'] = n_ratio
    print(f"   ‚Ä¢ NÂê´Èáè: {n_count} ({n_ratio*100:.1f}%) - ÂæóÂàÜ: {n_score:.0f}/100")
    
    # GCÂê´Èáè
    gc_count = sequence.count('G') + sequence.count('C')
    gc_content = gc_count / len(sequence)
    gc_score = max(0, 100 - abs(gc_content - 0.5) * 200)
    results['metrics']['gc_content'] = gc_content
    print(f"   ‚Ä¢ GCÂê´Èáè: {gc_content*100:.1f}% - ÂæóÂàÜ: {gc_score:.0f}/100")
    print(f"     ‚îî‚îÄ ÁîüÁâ©Â≠¶ÊúÄ‰ºòÂÄº: 50% (40-60%‰∏∫ÂêàÁêÜËåÉÂõ¥)")
    
    # Â∫èÂàóÂ§çÊùÇÂ∫¶
    counts = Counter(sequence)
    entropy = -sum((c/len(sequence))*math.log2(c/len(sequence)) 
                   for c in counts.values() if c > 0)
    max_entropy = math.log2(4)
    complexity_score = (entropy / max_entropy) * 100
    results['metrics']['entropy'] = entropy
    print(f"   ‚Ä¢ Â∫èÂàóÂ§çÊùÇÂ∫¶(ÁÜµ): {entropy:.3f}/{max_entropy:.3f} - ÂæóÂàÜ: {complexity_score:.0f}/100")
    
    # poly-XÊ£ÄÊµã
    max_poly = 0
    poly_details = []
    for nt in 'AGCTU':
        matches = re.findall(f'{nt}{{3,}}', sequence)
        if matches:
            max_len = max(len(m) for m in matches)
            max_poly = max(max_poly, max_len)
            poly_details.append(f"{nt}√ó{max_len}")
    
    poly_score = max(0, 100 - max_poly * 20)
    poly_grade = "‚úÖÊó†ÈóÆÈ¢ò" if max_poly <= 3 else "‚ö†Ô∏èÊúâÂêåËÅöÁâ©" if max_poly <= 5 else "‚ùå‰∏•Èáç"
    results['metrics']['max_poly'] = max_poly
    print(f"   ‚Ä¢ ÂêåËÅöÁâ©: ÊúÄÈïø{max_poly} ({', '.join(poly_details) if poly_details else 'Êó†'}) {poly_grade}")
    print(f"     ‚îî‚îÄ ÂæóÂàÜ: {poly_score:.0f}/100 (‚â§3‰∏∫ÂêàÊ†º)")
    
    sequence_quality_score = (n_score + gc_score + complexity_score + poly_score) / 4
    results['scores']['sequence_quality'] = sequence_quality_score
    print(f"\n   üìà Â∫èÂàóË¥®ÈáèÂæóÂàÜ: {sequence_quality_score:.1f}/100")
    
    # ===== 4. ÁªºÂêàËØÑÂàÜ =====
    print(f"\n{'='*80}")
    print(f"üéØ ÁªºÂêàËØÑÂàÜ (ÈíàÂØπRNA/DNAÈÄÇÈÖç‰ΩìËÆæËÆ°)")
    print(f"{'='*80}")
    
    # ÊùÉÈáçÈÖçÁΩÆ
    weights = {
        'structure_confidence': 0.50,  # ÁªìÊûÑÁΩÆ‰ø°Â∫¶ 50% (iPTM/iPAE‰∏∫‰∏ª)
        'secondary_structure': 0.30,   # ‰∫åÁ∫ßÁªìÊûÑ 30% (RNA/DNAÁâπÂºÇÊÄß)
        'sequence_quality': 0.20       # Â∫èÂàóË¥®Èáè 20%
    }
    
    final_score = (
        structure_conf_score * weights['structure_confidence'] +
        secondary_structure_score * weights['secondary_structure'] +
        sequence_quality_score * weights['sequence_quality']
    )
    
    results['final_score'] = final_score
    
    print(f"   ‚Ä¢ ÁªìÊûÑÁΩÆ‰ø°Â∫¶: {structure_conf_score:.1f}/100 (ÊùÉÈáç{weights['structure_confidence']*100:.0f}%)")
    print(f"   ‚Ä¢ ‰∫åÁ∫ßÁªìÊûÑ:   {secondary_structure_score:.1f}/100 (ÊùÉÈáç{weights['secondary_structure']*100:.0f}%)")
    print(f"   ‚Ä¢ Â∫èÂàóË¥®Èáè:   {sequence_quality_score:.1f}/100 (ÊùÉÈáç{weights['sequence_quality']*100:.0f}%)")
    print(f"\n   {'üèÜ ÊúÄÁªàÂæóÂàÜ:':<20} {final_score:.1f}/100\n")
    
    # ËØÑÁ∫ß
    if final_score >= 75:
        grade = "‚úÖ ‰ºòÁßÄ - Êé®ËçêÁî®‰∫éÂÆûÈ™åÈ™åËØÅ"
        grade_emoji = "üåü"
    elif final_score >= 60:
        grade = "‚ö†Ô∏è  ËâØÂ•Ω - ÂèØÂ∞ùËØïÔºåÂª∫ËÆÆ‰ºòÂåñ"
        grade_emoji = "üëç"
    elif final_score >= 45:
        grade = "‚ö†Ô∏è  ‰∏≠Á≠â - ÈúÄË¶ÅËøõ‰∏ÄÊ≠•‰ºòÂåñ"
        grade_emoji = "‚öôÔ∏è"
    else:
        grade = "‚ùå ‰∏çÂêàÊ†º - Âª∫ËÆÆÈáçÊñ∞ËÆæËÆ°"
        grade_emoji = "üî¥"
    
    results['grade'] = grade
    print(f"   {grade_emoji} {'ËØÑÁ∫ß:':<20} {grade}\n")
    
    # ===== 5. ÊîπËøõÂª∫ËÆÆ =====
    print(f"üí° ÊîπËøõÂª∫ËÆÆ:")
    
    if iptm < 0.5:
        results['recommendations'].append("iPTMËøá‰Ωé")
        print(f"   üî¥ iPTM={iptm:.2f} - ÈÄÇÈÖç‰Ωì‰∏éËõãÁôΩÁªìÂêàÂº±:")
        print(f"      ‚Ä¢ Â¢ûÂä† num_inter_contacts Âà∞ 3-4")
        print(f"      ‚Ä¢ ÂáèÂ∞è inter_chain_cutoff Âà∞ 18√Ö (Ë¶ÅÊ±ÇÊõ¥Á¥ßÂØÜÊé•Ëß¶)")
        print(f"      ‚Ä¢ Â¢ûÂä†ÈìæÈó¥Êé•Ëß¶ÊçüÂ§±ÊùÉÈáç")
        print(f"      ‚Ä¢ ËÄÉËôëÂª∂ÈïøÈÄÇÈÖç‰ΩìÈïøÂ∫¶Â¢ûÂä†Êé•Ëß¶Èù¢ÁßØ")
    
    if ipae_value and ipae_value > 12:
        results['recommendations'].append("iPAEËøáÈ´ò")
        print(f"   üü° iPAE={ipae_value:.1f}√Ö - ÈìæÈó¥Ë∑ùÁ¶ªËØØÂ∑ÆËæÉÂ§ß:")
        print(f"      ‚Ä¢ ‰ΩøÁî® distogram_only: false (ÂêØÁî®ConfidenceÊ®°Âùó)")
        print(f"      ‚Ä¢ Â¢ûÂä† recycling_steps Âà∞ 1-2")
    
    if secondary_structure_score < 60:
        results['recommendations'].append("‰∫åÁ∫ßÁªìÊûÑ‰∏çÁ®≥ÂÆö")
        print(f"   üü° MFE={results['metrics'].get('mfe', 0):.1f} - ‰∫åÁ∫ßÁªìÊûÑ‰∏çÂ§üÁ®≥ÂÆö:")
        print(f"      ‚Ä¢ Ë∞ÉÊï¥GCÂê´ÈáèÂà∞45-55%‰ª•Â¢ûÂº∫Á®≥ÂÆöÊÄß")
        print(f"      ‚Ä¢ ËÄÉËôëÊ∑ªÂä†Á¢±Âü∫ÈÖçÂØπÁ∫¶Êùü")
        print(f"      ‚Ä¢ Â¢ûÂä†ÈÄÇÈÖç‰ΩìÈïøÂ∫¶ÂÖÅËÆ∏Êõ¥Â§öÈÖçÂØπ")
    
    if max_poly > 4:
        results['recommendations'].append("ÂêåËÅöÁâ©ËøáÈïø")
        print(f"   üü° poly-X={max_poly} - ÂêåËÅöÁâ©ËøáÈïø:")
        print(f"      ‚Ä¢ Â¢ûÂä† poly_penalty ÊçüÂ§±ÊùÉÈáç")
        print(f"      ‚Ä¢ Â¢ûÂä† local_diversity Á∫¶Êùü")
    
    if gc_content < 0.35 or gc_content > 0.65:
        results['recommendations'].append("GCÂê´ÈáèÂºÇÂ∏∏")
        print(f"   üü° GC={gc_content*100:.0f}% - GCÂê´ÈáèÂÅèÁ¶ªÊúÄ‰ºòÂÄº:")
        print(f"      ‚Ä¢ Ë∞ÉÊï¥ gc_content_weight Âà∞ 0.15-0.20")
    
    if plddt < 0.6:
        results['recommendations'].append("Êï¥‰ΩìÁΩÆ‰ø°Â∫¶‰Ωé")
        print(f"   üü° pLDDT={plddt:.2f} - Êï¥‰ΩìÁªìÊûÑÁΩÆ‰ø°Â∫¶ËæÉ‰Ωé:")
        print(f"      ‚Ä¢ ËÆæÁΩÆ distogram_only: false")
        print(f"      ‚Ä¢ Â¢ûÂä†‰ºòÂåñËø≠‰ª£Ê¨°Êï∞")
        print(f"      ‚Ä¢ ÂáèÂ∞èÂ≠¶‰π†ÁéáÊèêÈ´òÊî∂ÊïõÁ®≥ÂÆöÊÄß")
    
    if not results['recommendations']:
        print(f"   ‚úÖ ËÆæËÆ°Ë¥®ÈáèËâØÂ•ΩÔºåÊó†ÊòéÊòæÈóÆÈ¢òÈúÄÊîπËøõ")
    
    print(f"\n{'='*80}\n")
    
    return results


def run_aptamer_structure_prediction(args, yaml_path, output_dir, boltz_model, sequence=None):
    """
    ËøêË°åÈÄÇÈÖç‰ΩìÁªìÊûÑÈ¢ÑÊµã - ‰øÆÊîπÁâàÔºàÊ∑ªÂä†ÂÆåÊï¥ËØÑ‰º∞Ôºâ
    """
    import sys
    sys.path.append('/home/yifan/boltz-for-RNA-DNA/boltz/src')
    from boltz.data.write.mmcif import to_mmcif
    from boltz.data.write.pdb import to_pdb
    
    # ËÆæÁΩÆÁªìÊûÑËæìÂá∫ÁõÆÂΩï
    if args.structure_output_dir:
        structure_dir = args.structure_output_dir
    else:
        structure_dir = os.path.join(output_dir, "structures")
    
    predictions_dir = os.path.join(structure_dir, "predictions")
    os.makedirs(predictions_dir, exist_ok=True)
    
    print(f"üî¨ ËøêË°åÈÄÇÈÖç‰ΩìÁªìÊûÑÈ¢ÑÊµã...")
    print(f"üìù ËæìÂÖ•YAML: {yaml_path}")
    print(f"üìÅ ËæìÂá∫ÁõÆÂΩï: {structure_dir}")
    
    try:
        # ‰ΩøÁî®boltzÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑ËøõË°åÁªìÊûÑÈ¢ÑÊµã
        print("üöÄ ÂºÄÂßãBoltzÁªìÊûÑÈ¢ÑÊµã...")
        
        # ÊûÑÂª∫boltzÂëΩ‰ª§
        boltz_cmd = [
            "boltz", "predict", yaml_path,
            "--out_dir", structure_dir,
            "--recycling_steps", str(args.recycling_steps),
            "--output_format", "mmcif"
        ]
        
        # ËøêË°åboltzÈ¢ÑÊµã
        result = subprocess.run(boltz_cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"‚ùå BoltzÂëΩ‰ª§ÊâßË°åÂ§±Ë¥•:")
            print(f"STDOUT: {result.stdout}")
            print(f"STDERR: {result.stderr}")
            raise RuntimeError(f"Boltz prediction failed")
        
        print("‚úÖ BoltzÁªìÊûÑÈ¢ÑÊµãÂÆåÊàê")
        
        # Êü•ÊâæÁîüÊàêÁöÑÊñá‰ª∂
        results = {
            'structure_dir': structure_dir,
            'files': {},
            'confidence': {},
            'evaluation': {}
        }
        
        # Êü•ÊâæCIFÊñá‰ª∂
        cif_files = glob.glob(os.path.join(structure_dir, "**", "*.cif"), recursive=True)
        if cif_files:
            cif_path = cif_files[0]
            results['files']['cif'] = cif_path
            print(f"üíæ ÊâæÂà∞CIFÊñá‰ª∂: {cif_path}")
            
            # ËΩ¨Êç¢PDB
            if args.output_format in ['pdb', 'both']:
                pdb_path = cif_path.replace('.cif', '.pdb')
                try:
                    from boltzdesign.utils import convert_cif_to_pdb
                    if convert_cif_to_pdb(cif_path, pdb_path):
                        results['files']['pdb'] = pdb_path
                        print(f"üíæ PDBÊñá‰ª∂Â∑≤ËΩ¨Êç¢: {pdb_path}")
                except Exception as e:
                    print(f"‚ö†Ô∏è PDBËΩ¨Êç¢Â§±Ë¥•: {e}")
        
        # Êü•ÊâæÁΩÆ‰ø°Â∫¶Êñá‰ª∂
        confidence_files = glob.glob(os.path.join(structure_dir, "**", "confidence_*.json"), recursive=True)
        if confidence_files:
            confidence_path = confidence_files[0]
            results['files']['confidence'] = confidence_path
            
            # ËØªÂèñÁΩÆ‰ø°Â∫¶‰ø°ÊÅØ
            try:
                with open(confidence_path, 'r') as f:
                    confidence_data = json.load(f)
                
                # ÊèêÂèñÊâÄÊúâÁΩÆ‰ø°Â∫¶ÊåáÊ†á
                results['confidence'] = {
                    'avg_plddt': confidence_data.get('complex_plddt', 0.0),
                    'iptm': confidence_data.get('iptm', 0.0),
                    'ptm': confidence_data.get('ptm', 0.0),
                    'ipae': (1 - confidence_data.get('iptm', 0.0)) * 31.0,  # ‰º∞ÁÆóipAE
                }
                
                print(f"üìä ÊâæÂà∞ÁΩÆ‰ø°Â∫¶Êñá‰ª∂: {confidence_path}")
                
                # Â¶ÇÊûúÊúâÂ∫èÂàóÔºåËøõË°åÁªºÂêàËØÑ‰º∞
                if sequence and 'N' not in sequence:
                    print("\n" + "="*80)
                    print("üî¨ ÂºÄÂßãÁªºÂêàË¥®ÈáèËØÑ‰º∞...")
                    print("="*80)
                    
                    evaluation_results = evaluate_aptamer_comprehensive(
                        confidence_path,
                        sequence,
                        args.aptamer_type,
                        cif_path
                    )
                    
                    results['evaluation'] = evaluation_results
                    
            except Exception as e:
                print(f"‚ö†Ô∏è ËØªÂèñÁΩÆ‰ø°Â∫¶Êñá‰ª∂Â§±Ë¥•: {e}")
        
        # ‰øùÂ≠ò‰ø°ÊÅØÊñá‰ª∂
        target_name = args.target_name or "aptamer"
        aptamer_name = f"aptamer_{args.aptamer_type.lower()}_{target_name}"
        coords_path = os.path.join(structure_dir, f"{aptamer_name}_info.npz")
        
        np.savez_compressed(
            coords_path,
            sequence=sequence if sequence else "",
            aptamer_type=args.aptamer_type,
            target_name=target_name,
            yaml_path=yaml_path,
            evaluation=results.get('evaluation', {})
        )
        results['files']['info'] = coords_path
        print(f"üìÅ ‰ø°ÊÅØÊñá‰ª∂Â∑≤‰øùÂ≠ò: {coords_path}")
        
        return results
        
    except Exception as e:
        print(f"‚ùå ÁªìÊûÑÈ¢ÑÊµãÂ§±Ë¥•: {str(e)}")
        import traceback
        traceback.print_exc()
        raise

def run_aptamer_structure_prediction_only(args):
    """
    Áã¨Á´ãÁöÑÈÄÇÈÖç‰ΩìÁªìÊûÑÈ¢ÑÊµãÊ®°Âºè
    ‰ªéÁé∞ÊúâÁöÑYAMLÊñá‰ª∂È¢ÑÊµãÁªìÊûÑ
    """
    print("üèóÔ∏è" + "="*80)
    print("üöÄ ÂêØÂä®ÈÄÇÈÖç‰ΩìÁªìÊûÑÈ¢ÑÊµãÊ®°Âºè")
    print("üèóÔ∏è" + "="*80)
    
    # È™åËØÅËæìÂÖ•Êñá‰ª∂
    if args.input_yaml:
        yaml_path = args.input_yaml
    else:
        # Â∞ùËØïËá™Âä®Êé®Êñ≠YAMLÊñá‰ª∂Ë∑ØÂæÑ
        if args.target_name and args.aptamer_type:
            work_dir = args.work_dir or os.getcwd()
            yaml_path = f'{work_dir}/outputs/aptamer_{args.aptamer_type.lower()}_{args.target_name}_{args.suffix}/aptamer_design.yaml'
        else:
            print("‚ùå ÈîôËØØ: ËØ∑Êèê‰æõ --input_yaml ÂèÇÊï∞ÊàñËÄÖ --target_name Âíå --aptamer_type ÂèÇÊï∞")
            return
    
    if not os.path.exists(yaml_path):
        print(f"‚ùå ÈîôËØØ: Êâæ‰∏çÂà∞YAMLÊñá‰ª∂: {yaml_path}")
        return
    
    print(f"üìù ËæìÂÖ•YAMLÊñá‰ª∂: {yaml_path}")
    
    # ËØªÂèñYAMLÊñá‰ª∂Ëé∑ÂèñÂ∫èÂàó‰ø°ÊÅØ
    try:
        with open(yaml_path, 'r') as f:
            yaml_data = yaml.safe_load(f)
        
        # ÊèêÂèñÈÄÇÈÖç‰ΩìÂ∫èÂàó
        aptamer_sequence = None
        for seq_entry in yaml_data.get('sequences', []):
            if args.aptamer_type.lower() in seq_entry:
                aptamer_sequence = seq_entry[args.aptamer_type.lower()].get('sequence', '')
                break
        
        if aptamer_sequence and 'N' not in aptamer_sequence:
            print(f"üß¨ Ê£ÄÊµãÂà∞ÈÄÇÈÖç‰ΩìÂ∫èÂàó: {aptamer_sequence}")
            print(f"üìè Â∫èÂàóÈïøÂ∫¶: {len(aptamer_sequence)}")
        else:
            print("‚ö†Ô∏è  Ë≠¶Âëä: Êú™ÊâæÂà∞ÊúâÊïàÁöÑÈÄÇÈÖç‰ΩìÂ∫èÂàóÊàñÂ∫èÂàóÂåÖÂê´Êú™Á°ÆÂÆöÁöÑÊ†∏Ëã∑ÈÖ∏(N)")
            aptamer_sequence = None
            
    except Exception as e:
        print(f"‚ùå ËØªÂèñYAMLÊñá‰ª∂Â§±Ë¥•: {e}")
        return
    
    # ËÆæÁΩÆGPUÁéØÂ¢É
    setup_gpu_environment(args.gpu_id)
    print(f"üñ•Ô∏è  ‰ΩøÁî®GPU: {args.gpu_id}")
    
    # Ê£ÄÊü•boltzÂëΩ‰ª§ÊòØÂê¶ÂèØÁî®
    try:
        result = subprocess.run(["boltz", "--help"], capture_output=True, text=True)
        if result.returncode != 0:
            print("‚ùå ÈîôËØØ: boltzÂëΩ‰ª§‰∏çÂèØÁî®ÔºåËØ∑Á°Æ‰øùÂ∑≤Ê≠£Á°ÆÂÆâË£ÖBoltz")
            return
        print("‚úÖ BoltzÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑Ê£ÄÊü•ÈÄöËøá")
        
    except FileNotFoundError:
        print("‚ùå ÈîôËØØ: Êâæ‰∏çÂà∞boltzÂëΩ‰ª§ÔºåËØ∑Á°Æ‰øùÂ∑≤Ê≠£Á°ÆÂÆâË£ÖBoltzÂπ∂Ê∑ªÂä†Âà∞PATH")
        return
    except Exception as e:
        print(f"‚ùå BoltzÂ∑•ÂÖ∑Ê£ÄÊü•Â§±Ë¥•: {e}")
        return
    
    # Á°ÆÂÆöËæìÂá∫ÁõÆÂΩï
    output_dir = os.path.dirname(yaml_path)
    if args.structure_output_dir:
        output_dir = args.structure_output_dir
    
    # ËøêË°åÁªìÊûÑÈ¢ÑÊµã
    try:
        print("\nüî¨ ÂºÄÂßãÁªìÊûÑÈ¢ÑÊµã...")
        structure_results = run_aptamer_structure_prediction(
            args, yaml_path, output_dir, None, aptamer_sequence
        )
        
        print(f"\n‚úÖ ÁªìÊûÑÈ¢ÑÊµãÂÆåÊàê!")
        print(f"üìÅ ÁªìÊûú‰øùÂ≠òÂú®: {structure_results['structure_dir']}")
        
        # ÊòæÁ§∫ÁîüÊàêÁöÑÊñá‰ª∂
        print("\nüìã ÁîüÊàêÁöÑÊñá‰ª∂:")
        for file_type, file_path in structure_results['files'].items():
            if file_path and os.path.exists(file_path):
                file_size = os.path.getsize(file_path) / 1024  # KB
                print(f"  üìÑ {file_type.upper()}: {os.path.basename(file_path)} ({file_size:.1f} KB)")
        
        # ÊòæÁ§∫ÁªìÊûÑË¥®Èáè‰ø°ÊÅØ
        if 'confidence' in structure_results:
            conf = structure_results['confidence']
            print(f"\nüìä ÁªìÊûÑË¥®ÈáèËØÑ‰º∞:")
            print(f"  üéØ Âπ≥ÂùápLDDT: {conf['avg_plddt']:.2f}")
            if conf['avg_plddt'] > 70:
                print("  ‚úÖ ÁªìÊûÑË¥®Èáè: È´òÁΩÆ‰ø°Â∫¶ (>70)")
            elif conf['avg_plddt'] > 50:
                print("  ‚ö†Ô∏è  ÁªìÊûÑË¥®Èáè: ‰∏≠Á≠âÁΩÆ‰ø°Â∫¶ (50-70)")
            else:
                print("  ‚ùå ÁªìÊûÑË¥®Èáè: ‰ΩéÁΩÆ‰ø°Â∫¶ (<50)")
        
        print(f"\nüéâ ÁªìÊûÑÈ¢ÑÊµãÊµÅÁ®ãÂÆåÊàê!")
        
    except Exception as e:
        print(f"‚ùå ÁªìÊûÑÈ¢ÑÊµãËøáÁ®ã‰∏≠Âá∫Áé∞ÈîôËØØ: {str(e)}")
        import traceback
        traceback.print_exc()


def show_aptamer_design_help():
    """ÊòæÁ§∫ÈÄÇÈÖç‰ΩìËÆæËÆ°ÁöÑ‰ΩøÁî®Â∏ÆÂä©"""
    print("""
üß¨ ÈÄÇÈÖç‰ΩìËÆæËÆ°Ê®°Âºè‰ΩøÁî®ÊåáÂçó:

1. RNAÈÄÇÈÖç‰ΩìËÆæËÆ° (ËõãÁôΩË¥®ÁõÆÊ†á):
   python boltzdesign1.py --design_mode aptamer --aptamer_type RNA \\
       --target_protein_seq "MKLLVVVGGVGSGKTTLLRQLAKEFG" \\
       --aptamer_length 40 --target_name myprotein --gpu_id 0

2. DNAÈÄÇÈÖç‰ΩìËÆæËÆ° (ËõãÁôΩË¥®ÁõÆÊ†á):
   python boltzdesign1.py --design_mode aptamer --aptamer_type DNA \\
       --target_protein_seq "MKLLVVVGGVGSGKTTLLRQLAKEFG" \\
       --aptamer_length 50 --target_name myprotein --gpu_id 0

3. RNAÈÄÇÈÖç‰ΩìËÆæËÆ° (Â∞èÂàÜÂ≠êÁõÆÊ†á):
   python boltzdesign1.py --design_mode aptamer --aptamer_type RNA \\
       --target_ligand_smiles "N[C@@H](Cc1ccc(O)cc1)C(=O)O" \\
       --aptamer_length 30 --target_name tyrosine --gpu_id 0

4. DNAÈÄÇÈÖç‰ΩìËÆæËÆ° (Â∞èÂàÜÂ≠êÁõÆÊ†á):
   python boltzdesign1.py --design_mode aptamer --aptamer_type DNA \\
       --target_ligand_smiles "CC(C)N(C(=O)CCC)C(C)c1ccccc1" \\
       --aptamer_length 35 --target_name drug --gpu_id 0

5. Áã¨Á´ãÁªìÊûÑÈ¢ÑÊµãÊ®°Âºè:
   python boltzdesign1.py --design_mode predict_structure \\
       --input_yaml "outputs/aptamer_dna_tyrosine_balanced_0/aptamer_design.yaml" \\
       --output_format both --gpu_id 0

ÂèÇÊï∞ËØ¥Êòé:
- --design_mode: protein(ÂéüÂßã), aptamer(ÈÄÇÈÖç‰ΩìËÆæËÆ°), predict_structure(‰ªÖÁªìÊûÑÈ¢ÑÊµã)
- --aptamer_type: RNA Êàñ DNA
- --target_protein_seq: ÁõÆÊ†áËõãÁôΩË¥®Â∫èÂàó (‰∏éSMILES‰∫åÈÄâ‰∏Ä)
- --target_ligand_smiles: ÁõÆÊ†áÂ∞èÂàÜÂ≠êSMILESÂ≠óÁ¨¶‰∏≤ (‰∏éËõãÁôΩË¥®Â∫èÂàó‰∫åÈÄâ‰∏Ä)
- --aptamer_length: ÈÄÇÈÖç‰ΩìÈïøÂ∫¶ (Êé®Ëçê20-80)
- --save_structures: ÊòØÂê¶‰øùÂ≠òÁªìÊûÑÊñá‰ª∂ (ÈªòËÆ§True)
- --output_format: ËæìÂá∫Ê†ºÂºè cif/pdb/both (ÈªòËÆ§both)
- --input_yaml: ÁªìÊûÑÈ¢ÑÊµãÊ®°ÂºèÁöÑËæìÂÖ•YAMLÊñá‰ª∂
""")

if __name__ == "__main__":
    main()
